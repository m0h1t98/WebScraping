{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/egbertbouman/youtube-comment-downloader\n",
    "def search_dict(partial, key):\n",
    "    \"\"\"\n",
    "    A handy function that searches for a specific `key` in a `partial` dictionary/list\n",
    "    \"\"\"\n",
    "    if isinstance(partial, dict):\n",
    "        for k, v in partial.items():\n",
    "            if k == key:\n",
    "                # found the key, return the value\n",
    "                yield v\n",
    "            else:\n",
    "                # value of the dict may be another dict, so we search there again\n",
    "                for o in search_dict(v, key):\n",
    "                    yield o\n",
    "    elif isinstance(partial, list):\n",
    "        # if the passed data is a list\n",
    "        # iterate over it & search for the key at the items in the list\n",
    "        for i in partial:\n",
    "            for o in search_dict(i, key):\n",
    "                yield o\n",
    "\n",
    "# from https://github.com/egbertbouman/youtube-comment-downloader\n",
    "def find_value(html, key, num_sep_chars=2, separator='\"'):\n",
    "    # define the start position by the position of the key + \n",
    "    # length of key + separator length (usually : and \")\n",
    "    start_pos = html.find(key) + len(key) + num_sep_chars\n",
    "    # the end position is the position of the separator (such as \")\n",
    "    # starting from the start_pos\n",
    "    end_pos = html.find(separator, start_pos)\n",
    "    # return the content in this range\n",
    "    return html[start_pos:end_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(url):\n",
    "    session = requests.Session()\n",
    "    # make the request\n",
    "    res = session.get(url)\n",
    "    \n",
    "    # extract the XSRF token\n",
    "    xsrf_token = find_value(res.text, \"XSRF_TOKEN\", num_sep_chars=3)\n",
    "    \n",
    "    # parse the YouTube initial data in the <script> tag\n",
    "    data_str = find_value(res.text, 'window[\"ytInitialData\"] = ', num_sep_chars=0, separator=\"\\n\").rstrip(\";\")\n",
    "    \n",
    "    # convert to Python dictionary instead of plain text string\n",
    "    data = json.loads(data_str)\n",
    "    \n",
    "    # search for the ctoken & continuation parameter fields\n",
    "    for r in search_dict(data, \"itemSectionRenderer\"):\n",
    "        pagination_data = next(search_dict(r, \"nextContinuationData\"))\n",
    "        if pagination_data:\n",
    "            \n",
    "            # if we got something, break out of the loop,\n",
    "            # we have the data we need\n",
    "            break\n",
    "    continuation_tokens = [(pagination_data['continuation'], pagination_data['clickTrackingParams'])]\n",
    "    \n",
    "    while continuation_tokens:\n",
    "        # keep looping until continuation tokens list is empty (no more comments)\n",
    "        continuation, itct = continuation_tokens.pop()\n",
    "        # construct params parameter (the ones in the URL)\n",
    "        params = {\n",
    "            \"action_get_comments\": 1,\n",
    "            \"pbj\": 1,\n",
    "            \"ctoken\": continuation,\n",
    "            \"continuation\": continuation,\n",
    "            \"itct\": itct,\n",
    "        }\n",
    "        # construct POST body data, which consists of the XSRF token\n",
    "        data = {\n",
    "            \"session_token\": xsrf_token,\n",
    "        }\n",
    "        # construct request headers\n",
    "        headers = {\n",
    "            \"x-youtube-client-name\": \"1\",\n",
    "            \"x-youtube-client-version\": \"2.20200731.02.01\"\n",
    "        }\n",
    "        # make the POST request to get the comments data\n",
    "        response = session.post(\"https://www.youtube.com/comment_service_ajax\", params=params, data=data, headers=headers)\n",
    "        # convert to a Python dictionary\n",
    "        comments_data = json.loads(response.text)\n",
    "        for comment in search_dict(comments_data, \"commentRenderer\"):\n",
    "            # iterate over loaded comments and yield useful info\n",
    "            yield {\n",
    "                \"commentId\": comment[\"commentId\"],\n",
    "                \"text\": ''.join([c['text'] for c in comment['contentText']['runs']]),\n",
    "                \"time\": comment['publishedTimeText']['runs'][0]['text'],\n",
    "                \"isLiked\": comment[\"isLiked\"],\n",
    "                \"likeCount\": comment[\"likeCount\"],\n",
    "                # \"replyCount\": comment[\"replyCount\"],\n",
    "                'author': comment.get('authorText', {}).get('simpleText', ''),\n",
    "                'channel': comment['authorEndpoint']['browseEndpoint']['browseId'],\n",
    "                'votes': comment.get('voteCount', {}).get('simpleText', '0'),\n",
    "                'photo': comment['authorThumbnail']['thumbnails'][-1]['url'],\n",
    "                \"authorIsChannelOwner\": comment[\"authorIsChannelOwner\"],\n",
    "            }\n",
    "        # load continuation tokens for next comments (ctoken & itct)\n",
    "        continuation_tokens = [(next_cdata['continuation'], next_cdata['clickTrackingParams'])\n",
    "                         for next_cdata in search_dict(comments_data, 'nextContinuationData')] + continuation_tokens\n",
    "        # avoid heavy loads with popular videos\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Vin√≠cius G',\n",
      " 'authorIsChannelOwner': False,\n",
      " 'channel': 'UCdwfpSSQz_Nn1nzfbN-n_QQ',\n",
      " 'commentId': 'UgzbFqQZ-DCjMONQYFN4AaABAg',\n",
      " 'isLiked': False,\n",
      " 'likeCount': 1,\n",
      " 'photo': 'https://yt3.ggpht.com/a/AATXAJxL1QwU5iqw9NctCu2fKIOuhtLzHkZkqwMRagzFOQ=s48-c-k-c0xffffffff-no-rj-mo',\n",
      " 'text': 'Help me a lot!',\n",
      " 'time': '1 month ago',\n",
      " 'votes': '1'}\n",
      "==================================================\n",
      "{'author': 'Maryam Ashraf',\n",
      " 'authorIsChannelOwner': False,\n",
      " 'channel': 'UCfcc9fBy567lENnf4F_qLuw',\n",
      " 'commentId': 'UgzJ0P5-c1aau128bLp4AaABAg',\n",
      " 'isLiked': False,\n",
      " 'likeCount': 0,\n",
      " 'photo': 'https://yt3.ggpht.com/a/AATXAJynJKScNtBFcuDCggBZ97eE-BIYsEO4tOnn9jZz8Q=s48-c-k-c0xffffffff-no-rj-mo',\n",
      " 'text': 'how to save the detected faces .....face detected from the saved '\n",
      "         'video of my laptop',\n",
      " 'time': '1 month ago',\n",
      " 'votes': '0'}\n",
      "==================================================\n",
      "{'author': 'yomama1938',\n",
      " 'authorIsChannelOwner': False,\n",
      " 'channel': 'UCB6t4UuE-tHA9CCRhCpYn_w',\n",
      " 'commentId': 'UgyxtPJYYlC-ma8vKJB4AaABAg',\n",
      " 'isLiked': False,\n",
      " 'likeCount': 2,\n",
      " 'photo': 'https://yt3.ggpht.com/a/AATXAJzplytBiNtp_8awqnMMjqgRU1J5aB8DWBzk2g=s48-c-k-c0xffffffff-no-rj-mo',\n",
      " 'text': 'Good',\n",
      " 'time': '6 months ago',\n",
      " 'votes': '2'}\n",
      "==================================================\n",
      "{'author': 'Axis Bank',\n",
      " 'authorIsChannelOwner': False,\n",
      " 'channel': 'UCbpve95GAKORE5NJUfCYETQ',\n",
      " 'commentId': 'UgySF_q0gd4oAFPZFC14AaABAg',\n",
      " 'isLiked': False,\n",
      " 'likeCount': 1,\n",
      " 'photo': 'https://yt3.ggpht.com/a/AATXAJypjM7hCwqwEi_8bU3IKoDHZpDHzmhDwfJg-Law=s48-c-k-c0xffffffff-no-rj-mo',\n",
      " 'text': 'Good',\n",
      " 'time': '7 months ago',\n",
      " 'votes': '1'}\n",
      "==================================================\n",
      "{'author': 'HyperCreeck',\n",
      " 'authorIsChannelOwner': False,\n",
      " 'channel': 'UCKWKXQOMdb6xEJ1Gx7-340g',\n",
      " 'commentId': 'UgwmCchuJoTI9Pnc6RB4AaABAg',\n",
      " 'isLiked': False,\n",
      " 'likeCount': 2,\n",
      " 'photo': 'https://yt3.ggpht.com/a/AATXAJxYrfmMKj8RnE_IDcwEApjQ3fEFklbdreCs0COcfA=s48-c-k-c0xffffffff-no-rj-mo',\n",
      " 'text': 'Hey, do you remember me?',\n",
      " 'time': '7 months ago',\n",
      " 'votes': '2'}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from pprint import pprint\n",
    "    url = \"https://www.youtube.com/watch?v=ta2CoAFQjHY\"\n",
    "    for count, comment in enumerate(get_comments(url)):\n",
    "        if count == 5:\n",
    "            break\n",
    "        pprint(comment)\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
